## Consolidated Examinable Topics and Concepts

*(Translated for Computer/LLM Use)*

---

### 1. Analysis of Algorithms

#### 1.1 Program Verification

* **Arguing Correctness:**
  Understanding how to prove that an algorithm solves the intended problem correctly (preconditions, postconditions, loop invariants).
* **Arguing Termination:**
  Methods for proving that an algorithm eventually halts (e.g., using a decreasing measure or variant function).

#### 1.2 Complexity Analysis

* Determining how runtime and memory usage scale with input size.
* Includes deriving exact and asymptotic runtime using counting, recurrence relations, and loop analysis.

##### 1.2.1 Common Recurrence Relations

* Standard recurrence patterns:

  * ( T(n) = T(n/2) + O(1) ) ‚Üí O(log n)
  * ( T(n) = 2T(n/2) + O(n) ) ‚Üí O(n log n)
  * ( T(n) = T(n-1) + O(1) ) ‚Üí O(n)
* Master theorem, recursion tree method, substitution method.

#### 1.3 Asymptotic Notation

* Big-O, Big-Œò, Big-Œ© definitions and relationships.
* Best, average, and worst-case analysis.
* Comparing growth rates.

#### 1.4 Measures of Complexity

* Time complexity vs. space complexity.
* Input size considerations (number of elements, bits, edges, vertices).
* Amortized analysis (e.g., array resizing).

#### 1.5 Analysis of Basic Sorting Algorithms

* **Selection Sort:** iterative selection of minimum; O(n¬≤).
* **Insertion Sort:** incremental insertion; O(n¬≤) worst, O(n) best (sorted).
* **Algorithms‚Äô Properties:**

  * Stability
  * In-place vs. not in-place
  * Adaptivity
  * Deterministic vs. randomized.

---

### 2. Divide and Conquer

* **Karatsuba‚Äôs Multiplication:** Sublinear integer multiplication O(n^1.585).
* **Merge Sort (Revision):** Divide-and-conquer sorting; recurrence T(n)=2T(n/2)+O(n)=O(n log n).
* **Counting Inversions:** Counting out-of-order pairs using modified merge sort.

---

### 3. Fast Sorting Algorithms

* **Heapsort (Revision):**

  * Uses binary heap.
  * O(n log n) time, O(1) space.
  * Not stable.

* **Quicksort:**

  * Partition-based sorting.
  * Average O(n log n), worst-case O(n¬≤).
  * Randomized pivot selection to avoid worst case.

* **Complexity Lower Bounds for Sorting:**

  * Decision tree proof: any comparison-based sorting requires Œ©(n log n).

* **Sorting Integers Fast:**

  * **Counting Sort:** O(n + k), uses frequency counting; stable.
  * **Radix Sort:** multi-pass stable sorting using Counting Sort on digits; O(d(n + k)).

---

### 4. Order Statistics and Selection

* **Order Statistics Problem:** Find the k-th smallest element.
* **Quickselect Algorithm:**

  * Partition-based selection.
  * Average O(n), worst O(n¬≤).
* **Randomized Pivot Selection:** Random pivot to improve expected time.
* **Median of Medians:** Deterministic O(n) selection algorithm.

---

### 5. Graph Basics

#### 5.1 Modelling with Graphs

* Definitions: vertex, edge, directed/undirected, weighted/unweighted.
* Representing real-world relationships (roads, dependencies).

#### 5.2 Representation and Storage

* **Adjacency matrix:** O(V¬≤) space.
* **Adjacency list:** O(V + E) space.
* Trade-offs in efficiency.

#### 5.3 Graph Traversal and Applications

* **Depth-First Search (DFS):**
  Recursive/backtracking traversal; used for connectivity and cycle detection.
* **Finding Connected Components:**
  Using DFS or BFS to label components in undirected graphs.
* **Cycle Finding:**
  Detect cycles in directed/undirected graphs via DFS.
* **Breadth-First Search (BFS):**
  Level-order traversal; O(V + E).

#### 5.4 Shortest Paths

* **Properties:** triangle inequality, optimal substructure.
* **Variants:** single-source, all-pairs, unweighted, weighted.
* **Unweighted Shortest Paths:**
  BFS gives minimum hop count.

#### 5.5 Topological Sorting

* **Kahn‚Äôs Algorithm:** Queue-based approach using indegrees.
* **DFS-based Topological Sort:** Post-order traversal on DAGs.

#### 5.6 Incremental Graph Connectivity

* **Union-Find Disjoint Set:**

  * Union by rank and path compression.
  * Applications: Kruskal‚Äôs MST, connectivity queries.

---

### 6. Greedy Algorithms

#### 6.1 Shortest Path (Non-negative Weights)

* **Dijkstra‚Äôs Algorithm:**

  * Greedy single-source shortest path.
  * O((V + E) log V) with priority queue.

#### 6.2 Minimum Spanning Trees

* **Prim‚Äôs Algorithm:** Greedy growth from start node; O(E log V).
* **Kruskal‚Äôs Algorithm:** Sort edges and add if no cycle (Union-Find); O(E log V).

---

### 7. Dynamic Programming

#### 7.1 Key Elements

* Optimal substructure and overlapping subproblems.
* Subproblem table design and recurrence formulation.

#### 7.2 Top-down vs. Bottom-up

* Recursive memoization vs. iterative tabulation.

#### 7.3 Reconstructing Optimal Solutions

* Storing decision choices for solution reconstruction.

#### 7.4 Unbounded Knapsack

* Items can be chosen multiple times; O(nW).

#### 7.5 0-1 Knapsack

* Choose each item once; O(nW).

#### 7.6 Edit Distance

* Minimum insertions/deletions/substitutions; O(mn).

#### 7.7 Matrix Chain Multiplication

* Optimal parenthesization using DP; O(n¬≥).

#### 7.8 Space-Saving Trick

* Reducing DP space by reusing limited rows or columns.

---

### 8. Dynamic Programming Graph Algorithms

#### 8.1 Shortest Paths with Negative Weights

* **Bellman-Ford Algorithm:** O(VE), detects negative cycles.

#### 8.2 All-Pairs Shortest Paths

* **Floyd-Warshall Algorithm:** O(V¬≥), handles negatives but no negative cycles.

#### 8.3 Transitive Closure

* Boolean reachability between all vertex pairs (using Floyd-Warshall variant).

#### 8.4 Critical Path Problem

* Longest path in DAG (using topological order).

---

### 9. Network Flow

#### 9.1 Ford-Fulkerson Algorithm

* Augmenting paths until saturation; O(E * max_flow).
* **Residual Network:** Represents remaining capacities.
* **Augmenting Paths:** Paths along which flow can increase.
* **DFS Implementation:** Common for small graphs.

#### 9.2 Minimum Cut Problem

* Partition graph into S and T minimizing total cut capacity.
* **Min-cut Max-flow Theorem:** Flow value equals cut capacity.

#### 9.3 Bipartite Matching

* Reduces matching problem to max flow formulation.

#### 9.4 Circulations with Demands and Lower Bounds

* Extension of max flow: each edge has lower and upper capacity bounds.

---

### 10. Search Trees

#### 10.1 Binary Search Trees (BST)

* In-order traversal yields sorted order.
* Average O(log n), worst O(n).

#### 10.2 AVL Trees

* Self-balancing BST; height difference ‚â§ 1.
* Rotations for rebalancing.

#### 10.3 2-3 Trees

* Nodes with 2 or 3 children; perfectly balanced search trees.

#### 10.4 Red-Black Trees

* Balanced BST using color properties.
* Height ‚â§ 2 log(n+1).

#### 10.5 Comparing AVL and Red-Black Trees

* AVL: faster lookups, slower inserts.
* RBT: faster inserts/deletes, used in libraries (e.g., maps/sets).

---

### 11. Prefix Tries and Suffix Trees

#### 11.1 Prefix Trie / Retrieval Tree

* Tree storing prefixes; O(L) search, insert, delete (L = word length).
* **Applications:** autocomplete, spell-check, dictionary compression.

#### 11.2 Suffix Trees

* Compact trie of all suffixes; O(n) space with Ukkonen‚Äôs algorithm.
* **Applications:** substring search, pattern matching, longest repeated substring.

---

### üîç Summary for AI/LLM Use

**Key algorithmic paradigms taught and examinable:**

* Verification (correctness, termination)
* Asymptotic analysis, recurrence solving
* Sorting (comparison-based and non-comparison)
* Divide and conquer
* Greedy and dynamic programming
* Graph theory and traversal
* Shortest paths (BFS, Dijkstra, Bellman-Ford, Floyd-Warshall)
* Minimum spanning trees (Prim, Kruskal)
* Network flow and matching
* Self-balancing trees
* Trie and suffix tree data structures

**Core problem-solving frameworks:**

* Inductive reasoning for correctness
* Recurrence and asymptotic bounding for complexity
* Reduction and transformation for optimization problems
* Dynamic programming recurrence formulation
* Graph modeling and flow decomposition

